# Evaluating-RAG-LLMs-for-Response-Quality
Evaluates Flan-T5, Qwen2.5, and LLaMA 3.2 in a shared RAG setup. Larger models yield better answer relevance and faithfulness on proprietary document queries.
